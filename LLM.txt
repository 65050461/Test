LLM คือ
Large Language Models หรือ LLM คือ โมเดลที่ใช้ประมวลผลข้อมูล และสร้างข้อมูลใหม่ ๆ ออกมา ซึ่งส่วนใหญ่จะเป็นโมเดลพื้นฐานของ Generative AI โดยมีความสามารถในการตอบคำถาม แปลภาษา คาดเดาคำศัพท์ หรือบริบทอื่น ๆ ทางภาษา ตัวอย่าง Application ที่ได้นำ LLM ไปใช้ ได้แก่ ChatGPT สำหรับตอบคำถาม ให้คำแนะนำ
Microsoft Copilot เพื่อช่วยร่างและวิเคราะห์ข้อมูล 
GitHub Copilot ช่วยเขียนโค้ด

และอีกหนึ่งสิ่งที่สามารถนำ LLM ไปประยุกต์ใช้ได้ ก็คือ Text-to-SQL

Text-to-SQL คือ การแปลงคำถามที่เป็นข้อความธรรมดา (Natural Language) ให้กลายเป็นคำสั่ง SQL Query
เช่น หากตั้งคำถามว่า ประเทศใดบ้างที่ใช้ภาษาอังกฤษและฝรั่งเศสเป็นภาษาทางการ ก็จะได้คำสั่ง Query ออกมา มีการใช้ select from where และมีการ join ตารางเข้าด้วยกันเพื่อให้ได้คำตอบออกมา

แต่ว่าการนำ LLM มาใช้กับ Text-to-SQL ยังเป็นเรื่องใหม่ ทำให้ยังมีข้อจำกัดอยู่หลายอย่าง ยกตัวอย่างเช่น

ข้อกำกัดของการนำ LLM มาใช้กับ Text-to-SQL
1. ช่องว่างระหว่างงานวิจัยกับโลกจริง
2. ความสัมพันธ์แบบผกผัน (Converse Relations)
3. ต้นทุนและความเป็นเจ้าของข้อมูล

เรามาดูข้อจำกัดไปทีละข้อกันครับ

(1.) ข้อแรก ซึ่งเป็นข้อที่สำคัญที่สุด คือ ช่องว่างระหว่างงานวิจัยกับโลกจริง
เนื่องจากชุดข้อมูลที่ใช้ Train เช่น SPIDER และ WikiSQL มีขนาดเล็กและไม่ได้สะท้อนความซับซ้อนของฐานข้อมูลจริง
ผู้วิจัยจึงได้พัฒนา BIg bench for laRge-scale Database หรือ BIRD เพื่อพิสูจย์ข้อจำกัดนี้ โดยที่ BIRD คือ ชุดข้อมูลสำหรับทดสอบโมเดล ซึ่งมีความท้าทายกว่าชุดข้อมูลที่เคยมีมา ประกอบไปด้วย 12,751 ตัวอย่างคำถาม SQL, ฐานข้อมูล 95 ชุด และ ครอบคลุม 37 โดเมน เช่น การเงิน, กีฬา, การศึกษา, สุขภาพ

เมื่อนำ GPT-4, Codex, และโมเดลอื่น ๆ มาทดสอบกับ BIRD
GPT-4 ทำได้ดีที่สุด แต่ยังมี ความแม่นยำเพียง 54.89% ขณะที่มนุษย์ทำได้ 92.96%

งานวิจัยนี้จึงสรุปผลได้ว่า
LLM ยังไม่สามารถเข้าใจฐานข้อมูลขนาดใหญ่ได้ดีพอ และการเชื่อมโยงข้อมูลจากตารางต่าง ๆ ยังมีข้อผิดพลาด

ต่อมาจึงมีคนนำงานวิจัย BIRD มาต่อยอด ด้วยการพัฒนา SQL-PaLM
SQL-PaLM คือ Framework ที่พัฒนาเพื่อเพิ่มประสิทธิภาพของ LLMs ในการทำ Text-to-SQL โดยใช้โมเดล PaLM-2
แนวทางของ SQL-PaLM ประกอบไปด้วย
1. Few-shot Prompting และ Execution-based Selection
2. Instruction Fine-tuning
3. Column Selection และ Schema Optimization

แนวทางที่ 1 คือ Few-shot Prompting และ Execution-based Selection
คือ การใช้ตัวอย่าง SQL ที่ถูกต้องเพื่อช่วยให้โมเดลสร้าง SQL ที่แม่นยำขึ้น
กระบวนการ มีดังนี้
1. Sampling SQL หลายตัวจากโมเดล → สร้าง SQL หลายรูปแบบ
2. ตรวจสอบความถูกต้องของ SQL ผ่าน Execution → รัน SQL และเช็คผลลัพธ์
3. เลือก SQL ที่ให้ผลลัพธ์ที่ถูกต้องที่สุด → กรอง SQL ที่รันไม่ผ่านและเลือก SQL ที่มีผลลัพธ์ถูกต้องมากที่สุด

แนวทางที่ 2 คือ Instruction Fine-tuning
คือ การปรับแต่งโมเดลให้เข้าใจ SQL ที่ซับซ้อนมากขึ้นโดยใช้ Supervised Learning ที่ฝึกกับข้อมูลที่หลากหลาย รวมถึง Synthetic Data
ประกอบด้วย
1. ขยายขอบเขตของข้อมูลที่ใช้ฝึก
	ใช้ BIRD ซึ่งมีฐานข้อมูลขนาดใหญ่และโครงสร้างซับซ้อน
	เพิ่มตัวอย่างที่มีการใช้ Aggregation, Subqueries และ Joins

2. เพิ่มข้อมูลฝึกที่สร้างเอง (Synthetic Data)
	สร้าง SQL หลายรูปแบบที่ได้ผลลัพธ์เดียวกัน
	ใช้ข้อมูลนี้เพื่อฝึกโมเดลให้รองรับ SQL ที่มีโครงสร้างหลากหลาย

3. ใช้การคัดกรองข้อมูลที่เกี่ยวข้อง
	ลดจำนวนคอลัมน์ที่ต้องใช้ โดยเลือกเฉพาะคอลัมน์ที่เกี่ยวข้องกับคำถาม

แนวทางที่ 3 คือ Column Selection และ Schema Optimization
เนื่องจากฐานข้อมูลขนาดใหญ่มีตารางและคอลัมน์จำนวนมาก ทำให้ LLM ประมวลผลได้ไม่ดี จึงใช้ Column Selection เพื่อลดขนาดข้อมูลที่ต้องประมวลผล
เทคนิคที่ใช้
1. Retrieval-based Column Selection
	ใช้ Nearest Neighbor Search เพื่อเลือกคอลัมน์ที่เกี่ยวข้องกับคำถาม

2. Program-aided Column Selection
	ใช้ LLM สร้าง SQL เบื้องต้น แล้วดึงเฉพาะคอลัมน์ที่ถูกใช้งานจริง

3. Soft & Hard Column Selection
	Soft Selection คือ การเน้นให้ความสำคัญกับคอลัมน์ที่สำคัญแต่ยังคงข้อมูลทั้งหมด
	Hard Selection คือ การตัดคอลัมน์ที่ไม่เกี่ยวข้องออก

ผลการทดสอบของ SQL-PaLM ได้ดังนี้
ในการทดสอบด้วยชุดข้อมูล SPIDER และ BIRD SQL-PaLM ที่ใช้กระบวนการ Fine-tuning จะได้ค่าความแม่นยำสูงสุด

ข้อสรุปของงานวิจัยนี้ คือ
SQL-PaLM เป็น Framework ที่พัฒนาให้ LLMs สร้าง SQL ที่แม่นยำและมีประสิทธิภาพมากขึ้น แต่ว่ายังต้องพัฒนาต่อไปเพื่อให้สามารถนำไปใช้งานได้จริง

(2.) ข้อสอง คือ ปัญหา Converse Relations (ความสัมพันธ์แบบผกผัน)
ตัวอย่างความสัมพันธ์แบบผกผัน เช่น "has part" → "is part of" "parent of" → "child of"
เนื่องจาก LLMs เข้าใจแค่สถิติของการใช้ข้อมูล ไม่ใช่โครงสร้างภาษาจริง ๆ ดังนั้นจึงใช้ ConvRe ซึ่งเป็นชุดข้อมูลใหม่ที่ออกแบบมาพื่อทดสอบความเข้าใจ Converse Relations ของ LLMs

ConvRe ประกอบด้วย 2 งานหลัก ที่ออกแบบให้เป็น Multiple-choice Question
1. Re2Text ให้ความสัมพันธ์ทางโครงสร้าง แล้วถามข้อความที่สื่อความหมายตรงกัน
2. Text2Re ให้ข้อความ แล้วถามความสัมพันธ์โครงสร้างที่ตรงกัน





ตัวอย่างการแก้ปัญหา
	1. ไม่สามารถใช้งานได้จริง - ทดสอบ BIRD กับโมเดล LLM ในปัจจุบันเพื่อให้เห็นภาพ
	แนวทางแก้ไข - ใช้ SQL-PaLM

	2. ปัญหา Converse Relations (ความสัมพันธ์แบบผกผัน) - ทดสอบด้วย Benchmark: ConvRe
	แนวทางแก้ไข - Hint CoT Few

	3. ข้อจำกัดด้านต้นทุนและความเป็นเจ้าของข้อมูล
	แนวทางแก้ไข - Weak and Strong LLMs

ความท้าทายและแนวทางในอนาคต